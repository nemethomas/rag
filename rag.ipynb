{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_community\n",
    "# conda create -n faiss_env python=3.12\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = ''\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.3, api_key=api_key)\n",
    "llm.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auf einere PDF-Datei\n",
    "def load_documents(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "pdf_path = '/Users/tom/Downloads/Netzneutralitaet.pdf'\n",
    "\n",
    "documents = load_documents(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Von einem Ordner\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader  # Falls PyPDFLoader nur über LangChain verfügbar ist\n",
    "\n",
    "def load_documents_from_folder(folder_path):\n",
    "    documents = []\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    found_paths = []\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        file_path = os.path.join(folder_path, pdf_file)\n",
    "        found_paths.append(file_path)  # Pfad zur Liste der gefundenen Pfade hinzufügen\n",
    "        \n",
    "        # Versuchen, das PDF mit PyPDFLoader zu laden\n",
    "        try:\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von {file_path}: {e}\")\n",
    "    \n",
    "    # Am Ende alle gefundenen Pfade ausgeben\n",
    "    print(\"Gefundene PDF-Dateien:\")\n",
    "    for path in found_paths:\n",
    "        print(path)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Beispielordner-Pfad\n",
    "folder_path = '/Users/tom/Dropbox/Text/'\n",
    "\n",
    "documents = load_documents_from_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into smaller chunks\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(len(split_docs))\n",
    "    return split_docs\n",
    "\n",
    "split_docs = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install faiss-cpu / faiss-gpu\n",
    "api_key = 'AIzaSyDMb9OfWYCeQncqbtBeODwkV8YQPvMivWQ'\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def get_vector_store(text_chunks):\n",
    "    texts = [chunk.page_content for chunk in text_chunks]  # Extract text content from the chunks\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\",google_api_key=api_key)\n",
    "    vector_store = FAISS.from_texts(texts, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "get_vector_store(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive_context(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\",google_api_key=api_key)\n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "    print(docs)\n",
    "    return docs\n",
    "\n",
    "retreive_context(\"Which topics are covered in the book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are an assistant for question-answering tasks.\"),\n",
    "    (\"human\", \"Use the following pieces of retrieved context to answer the question. \\n\\\n",
    "    If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. \\n\\\n",
    "    Question: {question} \\n\\\n",
    "    Context: {context} \\n \\\n",
    "    Answer:\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return docs[0].page_content\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": RunnableLambda(lambda x: retreive_context(x)) | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"Wer ist Bill Mollison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
